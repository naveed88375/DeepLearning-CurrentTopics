{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wTToWef4kllP",
    "outputId": "9b9969ff-e3a8-457d-b6a3-92daff32a49c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree... Done\n",
      "Reading state information... Done\n",
      "cmake is already the newest version (3.22.1-1ubuntu1.22.04.2).\n",
      "Suggested packages:\n",
      "  swig-doc swig-examples swig4.0-examples swig4.0-doc\n",
      "The following NEW packages will be installed:\n",
      "  swig swig4.0\n",
      "0 upgraded, 2 newly installed, 0 to remove and 45 not upgraded.\n",
      "Need to get 1,116 kB of archives.\n",
      "After this operation, 5,542 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig4.0 amd64 4.0.2-1ubuntu1 [1,110 kB]\n",
      "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig all 4.0.2-1ubuntu1 [5,632 B]\n",
      "Fetched 1,116 kB in 1s (1,367 kB/s)\n",
      "Selecting previously unselected package swig4.0.\n",
      "(Reading database ... 121918 files and directories currently installed.)\n",
      "Preparing to unpack .../swig4.0_4.0.2-1ubuntu1_amd64.deb ...\n",
      "Unpacking swig4.0 (4.0.2-1ubuntu1) ...\n",
      "Selecting previously unselected package swig.\n",
      "Preparing to unpack .../swig_4.0.2-1ubuntu1_all.deb ...\n",
      "Unpacking swig (4.0.2-1ubuntu1) ...\n",
      "Setting up swig4.0 (4.0.2-1ubuntu1) ...\n",
      "Setting up swig (4.0.2-1ubuntu1) ...\n",
      "Processing triggers for man-db (2.10.2-1) ...\n",
      "Collecting box2d-py==2.3.8\n",
      "  Downloading box2d-py-2.3.8.tar.gz (374 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.5/374.5 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Building wheels for collected packages: box2d-py\n",
      "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for box2d-py: filename=box2d_py-2.3.8-cp310-cp310-linux_x86_64.whl size=2349115 sha256=9856cd3a27ddc1f46df8ee03a900f56ec8f07f1f25726f9caa2503ffcdce2ef5\n",
      "  Stored in directory: /root/.cache/pip/wheels/47/01/d2/6a780da77ccb98b1d2facdd520a8d10838a03b590f6f8d50c0\n",
      "Successfully built box2d-py\n",
      "Installing collected packages: box2d-py\n",
      "Successfully installed box2d-py-2.3.8\n",
      "Requirement already satisfied: box2d-py in /usr/local/lib/python3.10/dist-packages (2.3.8)\n",
      "Requirement already satisfied: gym in /usr/local/lib/python3.10/dist-packages (0.25.2)\n",
      "Collecting gym\n",
      "  Downloading gym-0.26.2.tar.gz (721 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m721.7/721.7 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym) (1.25.2)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gym) (2.2.1)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym) (0.0.8)\n",
      "Building wheels for collected packages: gym\n",
      "  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827621 sha256=7c041843532a306f602d1d483e3628c9adfba6b6fdbbcc9496ebd0820ea2d50f\n",
      "  Stored in directory: /root/.cache/pip/wheels/b9/22/6d/3e7b32d98451b4cd9d12417052affbeeeea012955d437da1da\n",
      "Successfully built gym\n",
      "Installing collected packages: gym\n",
      "  Attempting uninstall: gym\n",
      "    Found existing installation: gym 0.25.2\n",
      "    Uninstalling gym-0.25.2:\n",
      "      Successfully uninstalled gym-0.25.2\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "dopamine-rl 4.0.9 requires gym<=0.25.2, but you have gym 0.26.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed gym-0.26.2\n"
     ]
    }
   ],
   "source": [
    "!apt-get install -y swig cmake\n",
    "!pip install box2d-py==2.3.8\n",
    "!pip install --no-cache-dir box2d-py\n",
    "!pip install --upgrade gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "m6j5mOl6kkHz"
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import gym\n",
    "import numpy as np\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "# Define the genetic algorithm parameters\n",
    "POPULATION_SIZE = 100\n",
    "NUM_GENERATIONS = 50\n",
    "MUTATION_RATE = 0.1\n",
    "\n",
    "# Define the Q-learning parameters\n",
    "LEARNING_RATE = 0.1\n",
    "DISCOUNT_FACTOR = 0.99\n",
    "EPSILON = 0.1\n",
    "\n",
    "# Define the environment and algorithm settings\n",
    "ENV_NAME = 'LunarLander-v2'\n",
    "LEARNING_ALGORITHM = 'DQN'  # Choose from 'Q-learning', 'DQN', 'REINFORCE', 'ES'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "foICaHz5kkH1"
   },
   "outputs": [],
   "source": [
    "# Function to create the environment\n",
    "def create_environment(env_name):\n",
    "    return gym.make(env_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "kVB6L4zOkkH1"
   },
   "outputs": [],
   "source": [
    "# Define the Agent class\n",
    "class Agent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.weights = np.random.rand(state_size, action_size)\n",
    "        self.fitness = [0, 0]  # Initialize with two objectives: reward and steps\n",
    "\n",
    "    def act(self, state):\n",
    "        # Epsilon-greedy policy for exploration\n",
    "        if np.random.rand() < EPSILON:\n",
    "            return np.random.randint(self.action_size)\n",
    "        else:\n",
    "            q_values = np.dot(state, self.weights)\n",
    "            return np.argmax(q_values)\n",
    "\n",
    "    def learn(self, state, action, reward, next_state, done):\n",
    "        # Update fitness based on reward and steps taken\n",
    "        self.fitness[0] += reward\n",
    "        self.fitness[1] += 1\n",
    "        if done:\n",
    "            self.fitness[1] += 1000  # Penalty for early termination\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "B2CikasMkkH1"
   },
   "outputs": [],
   "source": [
    "# Function to evaluate an agent\n",
    "def evaluate_agent(agent, env):\n",
    "    total_reward = 0\n",
    "    total_steps = 0\n",
    "    state = env.reset()\n",
    "    done = False\n",
    "    while not done:\n",
    "        action = agent.act(state)\n",
    "        next_state, reward, done, _ = env.step(action)\n",
    "        agent.learn(state, action, reward, next_state, done)\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "        total_steps += 1\n",
    "    agent.fitness = [-total_reward, total_steps]  # Negative reward for minimization\n",
    "    return agent.fitness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "MbkMHJuvkkH2"
   },
   "outputs": [],
   "source": [
    "# Function to evolve agents\n",
    "def evolve_agents(env, state_size, action_size):\n",
    "    # Initialize population\n",
    "    population = [Agent(state_size, action_size) for _ in range(POPULATION_SIZE)]\n",
    "\n",
    "    for generation in range(NUM_GENERATIONS):\n",
    "        # Evaluate each agent in parallel\n",
    "        with ProcessPoolExecutor() as executor:\n",
    "            fitness_results = list(executor.map(evaluate_agent, population, [env] * POPULATION_SIZE))\n",
    "\n",
    "        # Perform adaptive fitness evaluation using surrogate models\n",
    "        fitness_results = adapt_fitness_evaluation(fitness_results)\n",
    "\n",
    "        # Select parents for reproduction based on fitness\n",
    "        parents = select_parents(population, fitness_results)\n",
    "\n",
    "        # Check if we have enough parents\n",
    "        if len(parents) < 2:\n",
    "            raise ValueError(f\"Not enough parents selected: {len(parents)}. At least 2 needed.\")\n",
    "\n",
    "        # Generate offspring through crossover and mutation\n",
    "        offspring = []\n",
    "        while len(offspring) < POPULATION_SIZE:\n",
    "            parent1, parent2 = np.random.choice(parents, size=2, replace=False)\n",
    "            child = crossover(parent1, parent2)\n",
    "            child = mutate(child)\n",
    "            offspring.append(child)\n",
    "\n",
    "        # Replace old population with offspring\n",
    "        population = offspring\n",
    "\n",
    "        # Perform dynamic hyperparameter tuning\n",
    "        global MUTATION_RATE\n",
    "        MUTATION_RATE = adjust_hyperparameters(generation)\n",
    "\n",
    "        # Print average fitness for monitoring\n",
    "        avg_reward = np.mean([fit[0] for fit in fitness_results])\n",
    "        avg_steps = np.mean([fit[1] for fit in fitness_results])\n",
    "        print(f\"Generation {generation + 1}, Average Reward: {avg_reward}, Average Steps: {avg_steps}, Mutation Rate: {MUTATION_RATE}\")\n",
    "\n",
    "    # Return the best agent after evolution\n",
    "    return max(population, key=lambda x: x.fitness[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3N0B8u9gkkH2"
   },
   "outputs": [],
   "source": [
    "# Function for adaptive fitness evaluation\n",
    "def adapt_fitness_evaluation(fitness_results):\n",
    "    # Example of adaptive fitness evaluation using surrogate models\n",
    "    # Here, we simply scale the fitness values for demonstration purposes\n",
    "    scaled_fitness = []\n",
    "    max_reward = max(fit[0] for fit in fitness_results)\n",
    "    max_steps = max(fit[1] for fit in fitness_results)\n",
    "    for fit in fitness_results:\n",
    "        scaled_reward = fit[0] / max_reward\n",
    "        scaled_steps = fit[1] / max_steps\n",
    "        scaled_fitness.append([scaled_reward, scaled_steps])\n",
    "    return scaled_fitness\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "laHRV9UvkkH2"
   },
   "outputs": [],
   "source": [
    "# Function to select parents based on fitness\n",
    "def select_parents(population, fitness_results):\n",
    "    # Select parents based on Pareto dominance\n",
    "    parents = []\n",
    "    for agent, fitness in zip(population, fitness_results):\n",
    "        dominated = False\n",
    "        for other_agent, other_fitness in zip(population, fitness_results):\n",
    "            if agent is not other_agent and dominates(fitness, other_fitness):\n",
    "                dominated = True\n",
    "                break\n",
    "        if not dominated:\n",
    "            parents.append(agent)\n",
    "    return parents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "fLMRRLIhkkH2"
   },
   "outputs": [],
   "source": [
    "# Function to check Pareto dominance\n",
    "def dominates(fitness1, fitness2):\n",
    "    # Check if fitness1 dominates fitness2 in a Pareto sense\n",
    "    return all(fit1 <= fit2 for fit1, fit2 in zip(fitness1, fitness2)) and any(fit1 < fit2 for fit1, fit2 in zip(fitness1, fitness2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "bEzXSQDRkkH2"
   },
   "outputs": [],
   "source": [
    "# Function to perform crossover between two parents\n",
    "def crossover(parent1, parent2):\n",
    "    # Perform single-point crossover\n",
    "    crossover_point = np.random.randint(0, parent1.state_size)\n",
    "    child_weights = np.concatenate([parent1.weights[:crossover_point], parent2.weights[crossover_point:]])\n",
    "    child = Agent(parent1.state_size, parent1.action_size)\n",
    "    child.weights = child_weights\n",
    "    return child\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "jNt8oRuZkkH2"
   },
   "outputs": [],
   "source": [
    "# Function to mutate an agent\n",
    "def mutate(agent):\n",
    "    # Perform random mutation\n",
    "    for i in range(agent.state_size):\n",
    "        for j in range(agent.action_size):\n",
    "            if np.random.rand() < MUTATION_RATE:\n",
    "                agent.weights[i, j] += np.random.normal(scale=0.1)\n",
    "    return agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "u6nUA3xCkkH2"
   },
   "outputs": [],
   "source": [
    "# Function to adjust hyperparameters\n",
    "def adjust_hyperparameters(generation):\n",
    "    # Example of dynamic hyperparameter tuning\n",
    "    # Here, we define a custom rule to adjust mutation rate based on generation\n",
    "    if generation < NUM_GENERATIONS / 2:\n",
    "        return 0.1\n",
    "    else:\n",
    "        return 0.05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 704
    },
    "id": "ctg9N9DLkkH3",
    "outputId": "e1f1f7cf-f720-4546-ac6a-986733f5644a"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31m_RemoteTraceback\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;31m_RemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 246, in _process_worker\n    r = call_item.fn(*call_item.args, **call_item.kwargs)\n  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 205, in _process_chunk\n    return [fn(*args) for args in chunk]\n  File \"/usr/lib/python3.10/concurrent/futures/process.py\", line 205, in <listcomp>\n    return [fn(*args) for args in chunk]\n  File \"<ipython-input-5-d99e3737a21b>\", line 8, in evaluate_agent\n    action = agent.act(state)\n  File \"<ipython-input-4-a048b664842b>\", line 14, in act\n    q_values = np.dot(state, self.weights)\nValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-84a6d0d2c974>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Run the main function if this is the main module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-84a6d0d2c974>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mstate_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0maction_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mbest_agent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevolve_agents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best Agent Found!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mevaluate_agent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-1309f8e6a86c>\u001b[0m in \u001b[0;36mevolve_agents\u001b[0;34m(env, state_size, action_size)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# Evaluate each agent in parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mProcessPoolExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mfitness_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_agent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpopulation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mPOPULATION_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# Perform adaptive fitness evaluation using surrogate models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/process.py\u001b[0m in \u001b[0;36m_chain_from_iterable_of_lists\u001b[0;34m(iterable)\u001b[0m\n\u001b[1;32m    573\u001b[0m     \u001b[0mcareful\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mto\u001b[0m \u001b[0mkeep\u001b[0m \u001b[0mreferences\u001b[0m \u001b[0mto\u001b[0m \u001b[0myielded\u001b[0m \u001b[0mobjects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \"\"\"\n\u001b[0;32m--> 575\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0melement\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m         \u001b[0melement\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0melement\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    619\u001b[0m                     \u001b[0;31m# Careful not to keep a reference to the popped future\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 621\u001b[0;31m                         \u001b[0;32myield\u001b[0m \u001b[0m_result_or_cancel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    622\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    623\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0m_result_or_cancel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m_result_or_cancel\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0mfut\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcancel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    456\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCancelledError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mFINISHED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.10/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0;31m# Break a reference cycle with the exception in self._exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "# Main function to execute the algorithm\n",
    "def main():\n",
    "    env = create_environment(ENV_NAME)\n",
    "    state_size = env.observation_space.shape[0]\n",
    "    action_size = env.action_space.n\n",
    "    best_agent = evolve_agents(env, state_size, action_size)\n",
    "    print(\"Best Agent Found!\")\n",
    "    evaluate_agent(best_agent, env)\n",
    "    env.close()\n",
    "\n",
    "# Run the main function if this is the main module\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
