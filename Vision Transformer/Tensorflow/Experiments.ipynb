{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Code test.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMbyEvCflvMJr4xgAIMQw+D"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["#Install Required Packages"],"metadata":{"id":"psIHTAaEGH52"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"20iXSPaAGDMC"},"outputs":[],"source":["%%capture\n","!pip install -U tensorflow-addons"]},{"cell_type":"markdown","source":["#Fashion MNIST Dataset\n","##Tiny Models"],"metadata":{"id":"TMwqwI2wGUAO"}},{"cell_type":"code","source":["#Model training\n","!python train.py tiny fashion_mnist\n","\n","#Model testing\n","!python test.py tiny fashion_mnist"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"phVLH3AUGEpa","executionInfo":{"status":"ok","timestamp":1650580902265,"user_tz":-300,"elapsed":2304363,"user":{"displayName":"Naveed Khan","userId":"05394460902808852358"}},"outputId":"9b5336cb-a7e3-4899-98bb-eafaae325592"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n","\r16384/29515 [===============>..............] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32768/29515 [=================================] - 0s 0us/step\n","\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r40960/29515 [=========================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n","26427392/26421880 [==============================] - 0s 0us/step\n","26435584/26421880 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n","16384/5148 [===============================================================================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n","4423680/4422102 [==============================] - 0s 0us/step\n","4431872/4422102 [==============================] - 0s 0us/step\n","2022-04-21 22:03:25.873009: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2022-04-21 22:40:56.864092: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n","WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, query_layer_call_fn while saving (showing 5 of 52). These functions will not be directly callable after loading.\n","2022-04-21 22:41:10.354336: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","CNN model performance is as given below.\n","              precision    recall  f1-score   support\n","\n","           0       0.80      0.87      0.83      1000\n","           1       0.99      0.97      0.98      1000\n","           2       0.80      0.88      0.83      1000\n","           3       0.88      0.90      0.89      1000\n","           4       0.86      0.80      0.83      1000\n","           5       0.97      0.97      0.97      1000\n","           6       0.78      0.67      0.72      1000\n","           7       0.95      0.98      0.96      1000\n","           8       0.95      0.97      0.96      1000\n","           9       0.98      0.96      0.97      1000\n","\n","    accuracy                           0.90     10000\n","   macro avg       0.90      0.90      0.89     10000\n","weighted avg       0.90      0.90      0.89     10000\n","\n","313/313 [==============================] - 1s 3ms/step - loss: 0.4179 - accuracy: 0.8958\n","CNN model loss on test set is: 0.4178882837295532\n","Transformer model performance is as given below.\n","              precision    recall  f1-score   support\n","\n","           0       0.79      0.92      0.85      1000\n","           1       1.00      0.97      0.98      1000\n","           2       0.87      0.88      0.87      1000\n","           3       0.90      0.88      0.89      1000\n","           4       0.83      0.86      0.85      1000\n","           5       1.00      0.95      0.97      1000\n","           6       0.78      0.65      0.71      1000\n","           7       0.92      0.98      0.95      1000\n","           8       0.98      0.98      0.98      1000\n","           9       0.96      0.95      0.95      1000\n","\n","    accuracy                           0.90     10000\n","   macro avg       0.90      0.90      0.90     10000\n","weighted avg       0.90      0.90      0.90     10000\n","\n","313/313 [==============================] - 10s 29ms/step - loss: 0.2696 - accuracy: 0.9021 - top-5-accuracy: 0.9987\n","Transformer model loss on test set is: 0.2695922255516052\n"]}]},{"cell_type":"markdown","source":["##Small Models"],"metadata":{"id":"pE-PLKoIGvb2"}},{"cell_type":"code","source":["#Model training\n","!python train.py small fashion_mnist\n","\n","#Model testing\n","!python test.py small fashion_mnist"],"metadata":{"id":"AengKkdJGwyo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650619694001,"user_tz":-300,"elapsed":1543913,"user":{"displayName":"Naveed Khan","userId":"05394460902808852358"}},"outputId":"7ef8b09e-c0e4-4f16-d001-f201b5e4c2b5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n","\r16384/29515 [===============>..............] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r32768/29515 [=================================] - 0s 0us/step\n","\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r40960/29515 [=========================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n","26427392/26421880 [==============================] - 0s 0us/step\n","26435584/26421880 [==============================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n","16384/5148 [===============================================================================================] - 0s 0us/step\n","Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n","4423680/4422102 [==============================] - 0s 0us/step\n","4431872/4422102 [==============================] - 0s 0us/step\n","2022-04-22 09:02:36.432279: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2022-04-22 09:27:32.842111: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n","WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, query_layer_call_fn while saving (showing 5 of 76). These functions will not be directly callable after loading.\n","2022-04-22 09:27:46.108295: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","CNN model performance is as given below.\n","              precision    recall  f1-score   support\n","\n","           0       0.83      0.83      0.83      1000\n","           1       0.98      0.97      0.98      1000\n","           2       0.84      0.80      0.82      1000\n","           3       0.90      0.88      0.89      1000\n","           4       0.79      0.85      0.82      1000\n","           5       0.97      0.98      0.97      1000\n","           6       0.69      0.67      0.68      1000\n","           7       0.93      0.97      0.95      1000\n","           8       0.96      0.97      0.96      1000\n","           9       0.98      0.94      0.96      1000\n","\n","    accuracy                           0.89     10000\n","   macro avg       0.89      0.89      0.89     10000\n","weighted avg       0.89      0.89      0.89     10000\n","\n","313/313 [==============================] - 1s 2ms/step - loss: 0.3854 - accuracy: 0.8865\n","CNN model loss on test set is: 0.38538697361946106\n","Transformer model performance is as given below.\n","              precision    recall  f1-score   support\n","\n","           0       0.89      0.82      0.85      1000\n","           1       1.00      0.97      0.98      1000\n","           2       0.85      0.87      0.86      1000\n","           3       0.91      0.88      0.90      1000\n","           4       0.77      0.92      0.84      1000\n","           5       1.00      0.95      0.97      1000\n","           6       0.73      0.68      0.71      1000\n","           7       0.93      0.97      0.95      1000\n","           8       0.99      0.97      0.98      1000\n","           9       0.96      0.96      0.96      1000\n","\n","    accuracy                           0.90     10000\n","   macro avg       0.90      0.90      0.90     10000\n","weighted avg       0.90      0.90      0.90     10000\n","\n","313/313 [==============================] - 6s 18ms/step - loss: 0.2692 - accuracy: 0.9008 - top-5-accuracy: 0.9989\n","Transformer model loss on test set is: 0.26915493607521057\n"]}]},{"cell_type":"markdown","source":["##Base Models"],"metadata":{"id":"DBktId0ZG1lE"}},{"cell_type":"code","source":["#Model training\n","!python train.py base fashion_mnist\n","\n","#Model testing\n","!python test.py base fashion_mnist"],"metadata":{"id":"XzdBWrRYG2zM","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650621719554,"user_tz":-300,"elapsed":1987246,"user":{"displayName":"Naveed Khan","userId":"05394460902808852358"}},"outputId":"b4c7279a-e8ba-480d-d78c-d946cd77c79f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2022-04-22 09:28:55.496931: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2022-04-22 10:01:14.584004: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n","WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, query_layer_call_fn while saving (showing 5 of 100). These functions will not be directly callable after loading.\n","2022-04-22 10:01:28.130443: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","CNN model performance is as given below.\n","              precision    recall  f1-score   support\n","\n","           0       0.81      0.83      0.82      1000\n","           1       0.97      0.97      0.97      1000\n","           2       0.81      0.81      0.81      1000\n","           3       0.86      0.90      0.88      1000\n","           4       0.84      0.76      0.80      1000\n","           5       0.98      0.95      0.97      1000\n","           6       0.69      0.66      0.67      1000\n","           7       0.90      0.98      0.94      1000\n","           8       0.93      0.98      0.95      1000\n","           9       0.97      0.91      0.94      1000\n","\n","    accuracy                           0.88     10000\n","   macro avg       0.88      0.88      0.88     10000\n","weighted avg       0.88      0.88      0.88     10000\n","\n","313/313 [==============================] - 1s 2ms/step - loss: 0.4772 - accuracy: 0.8766\n","CNN model loss on test set is: 0.4772002398967743\n","Transformer model performance is as given below.\n","              precision    recall  f1-score   support\n","\n","           0       0.87      0.85      0.86      1000\n","           1       1.00      0.97      0.99      1000\n","           2       0.85      0.87      0.86      1000\n","           3       0.93      0.89      0.91      1000\n","           4       0.84      0.85      0.85      1000\n","           5       0.99      0.97      0.98      1000\n","           6       0.71      0.76      0.73      1000\n","           7       0.96      0.95      0.95      1000\n","           8       0.99      0.98      0.98      1000\n","           9       0.94      0.97      0.96      1000\n","\n","    accuracy                           0.91     10000\n","   macro avg       0.91      0.91      0.91     10000\n","weighted avg       0.91      0.91      0.91     10000\n","\n","313/313 [==============================] - 8s 23ms/step - loss: 0.2577 - accuracy: 0.9051 - top-5-accuracy: 0.9989\n","Transformer model loss on test set is: 0.2576724588871002\n"]}]},{"cell_type":"markdown","source":["#CIFAR 10 Dataset\n","##Tiny Models"],"metadata":{"id":"6p2GVwx7HEPy"}},{"cell_type":"code","source":["#Model training\n","!python train.py tiny cifar10\n","\n","#Model testing\n","!python test.py tiny cifar10"],"metadata":{"id":"J01u1xgVHFf1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650625494125,"user_tz":-300,"elapsed":1800032,"user":{"displayName":"Naveed Khan","userId":"05394460902808852358"}},"outputId":"2da10d45-5adf-47af-9728-c50826d4e825"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n","170500096/170498071 [==============================] - 2s 0us/step\n","170508288/170498071 [==============================] - 2s 0us/step\n","2022-04-22 10:35:04.268277: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2022-04-22 11:04:07.962382: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n","WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, query_layer_call_fn while saving (showing 5 of 52). These functions will not be directly callable after loading.\n","2022-04-22 11:04:22.485077: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","CNN model performance is as given below.\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00      1000\n","           1       0.00      0.00      0.00      1000\n","           2       0.10      1.00      0.18      1000\n","           3       0.00      0.00      0.00      1000\n","           4       0.00      0.00      0.00      1000\n","           5       0.00      0.00      0.00      1000\n","           6       0.00      0.00      0.00      1000\n","           7       0.00      0.00      0.00      1000\n","           8       0.00      0.00      0.00      1000\n","           9       0.00      0.00      0.00      1000\n","\n","    accuracy                           0.10     10000\n","   macro avg       0.01      0.10      0.02     10000\n","weighted avg       0.01      0.10      0.02     10000\n","\n","313/313 [==============================] - 1s 3ms/step - loss: 2.3026 - accuracy: 0.1000\n","CNN model loss on test set is: 2.3025894165039062\n","Transformer model performance is as given below.\n","              precision    recall  f1-score   support\n","\n","           0       0.79      0.81      0.80      1000\n","           1       0.89      0.87      0.88      1000\n","           2       0.79      0.65      0.71      1000\n","           3       0.60      0.60      0.60      1000\n","           4       0.74      0.74      0.74      1000\n","           5       0.69      0.64      0.66      1000\n","           6       0.81      0.86      0.84      1000\n","           7       0.83      0.84      0.84      1000\n","           8       0.84      0.89      0.86      1000\n","           9       0.81      0.87      0.84      1000\n","\n","    accuracy                           0.78     10000\n","   macro avg       0.78      0.78      0.78     10000\n","weighted avg       0.78      0.78      0.78     10000\n","\n","313/313 [==============================] - 10s 29ms/step - loss: 0.6351 - accuracy: 0.7786 - top-5-accuracy: 0.9869\n","Transformer model loss on test set is: 0.6351076364517212\n"]}]},{"cell_type":"markdown","source":["##Small Models"],"metadata":{"id":"hAuK7uW3HVmk"}},{"cell_type":"code","source":["#Model training\n","!python train.py small cifar10\n","\n","#Model testing\n","!python test.py small cifar10"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c9ll_Ztn1Ir7","executionInfo":{"status":"ok","timestamp":1650628061856,"user_tz":-300,"elapsed":2567746,"user":{"displayName":"Naveed Khan","userId":"05394460902808852358"}},"outputId":"33529901-647e-4732-c464-3c526d2a8182"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2022-04-22 11:04:57.874929: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2022-04-22 11:46:37.379174: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n","WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, query_layer_call_fn while saving (showing 5 of 76). These functions will not be directly callable after loading.\n","2022-04-22 11:46:53.709112: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","CNN model performance is as given below.\n","              precision    recall  f1-score   support\n","\n","           0       0.64      0.65      0.65      1000\n","           1       0.75      0.69      0.72      1000\n","           2       0.44      0.48      0.46      1000\n","           3       0.39      0.42      0.40      1000\n","           4       0.47      0.48      0.47      1000\n","           5       0.46      0.47      0.47      1000\n","           6       0.60      0.73      0.66      1000\n","           7       0.65      0.59      0.62      1000\n","           8       0.74      0.68      0.70      1000\n","           9       0.76      0.60      0.67      1000\n","\n","    accuracy                           0.58     10000\n","   macro avg       0.59      0.58      0.58     10000\n","weighted avg       0.59      0.58      0.58     10000\n","\n","313/313 [==============================] - 1s 3ms/step - loss: 1.7432 - accuracy: 0.5794\n","CNN model loss on test set is: 1.7432491779327393\n","Transformer model performance is as given below.\n","              precision    recall  f1-score   support\n","\n","           0       0.82      0.80      0.81      1000\n","           1       0.88      0.86      0.87      1000\n","           2       0.74      0.66      0.70      1000\n","           3       0.56      0.63      0.59      1000\n","           4       0.73      0.78      0.75      1000\n","           5       0.65      0.69      0.67      1000\n","           6       0.79      0.85      0.82      1000\n","           7       0.90      0.77      0.83      1000\n","           8       0.87      0.88      0.87      1000\n","           9       0.84      0.83      0.84      1000\n","\n","    accuracy                           0.77     10000\n","   macro avg       0.78      0.77      0.78     10000\n","weighted avg       0.78      0.77      0.78     10000\n","\n","313/313 [==============================] - 14s 41ms/step - loss: 0.6415 - accuracy: 0.7742 - top-5-accuracy: 0.9855\n","Transformer model loss on test set is: 0.6414515972137451\n"]}]},{"cell_type":"markdown","source":["##Base Models"],"metadata":{"id":"3L_bYlRkHZdW"}},{"cell_type":"code","source":["#Model training\n","!python train.py base cifar10\n","\n","#Model testing\n","!python test.py base cifar10"],"metadata":{"id":"8EgHQcEWHb7s","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650631448630,"user_tz":-300,"elapsed":3386786,"user":{"displayName":"Naveed Khan","userId":"05394460902808852358"}},"outputId":"cb4c7d81-2667-430a-940a-55050ae3f939"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2022-04-22 11:47:45.662226: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2022-04-22 12:42:57.329522: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n","WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, query_layer_call_fn while saving (showing 5 of 100). These functions will not be directly callable after loading.\n","2022-04-22 12:43:14.365801: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","CNN model performance is as given below.\n","              precision    recall  f1-score   support\n","\n","           0       0.72      0.65      0.68      1000\n","           1       0.80      0.78      0.79      1000\n","           2       0.54      0.57      0.56      1000\n","           3       0.44      0.50      0.47      1000\n","           4       0.62      0.64      0.63      1000\n","           5       0.57      0.58      0.58      1000\n","           6       0.74      0.76      0.75      1000\n","           7       0.73      0.70      0.72      1000\n","           8       0.75      0.79      0.77      1000\n","           9       0.80      0.69      0.74      1000\n","\n","    accuracy                           0.67     10000\n","   macro avg       0.67      0.67      0.67     10000\n","weighted avg       0.67      0.67      0.67     10000\n","\n","313/313 [==============================] - 1s 4ms/step - loss: 1.8787 - accuracy: 0.6654\n","CNN model loss on test set is: 1.8787455558776855\n","Transformer model performance is as given below.\n","              precision    recall  f1-score   support\n","\n","           0       0.77      0.85      0.81      1000\n","           1       0.85      0.89      0.87      1000\n","           2       0.77      0.66      0.71      1000\n","           3       0.62      0.51      0.56      1000\n","           4       0.74      0.76      0.75      1000\n","           5       0.64      0.73      0.68      1000\n","           6       0.81      0.86      0.83      1000\n","           7       0.82      0.82      0.82      1000\n","           8       0.90      0.85      0.87      1000\n","           9       0.83      0.84      0.84      1000\n","\n","    accuracy                           0.78     10000\n","   macro avg       0.78      0.78      0.77     10000\n","weighted avg       0.78      0.78      0.77     10000\n","\n","313/313 [==============================] - 18s 51ms/step - loss: 0.6329 - accuracy: 0.7764 - top-5-accuracy: 0.9864\n","Transformer model loss on test set is: 0.6328871846199036\n"]}]},{"cell_type":"markdown","source":["#CIFAR 100 Dataset\n","#Tiny Models"],"metadata":{"id":"M3gF0F_xgsJ-"}},{"cell_type":"code","source":["#Model training\n","!python train.py tiny cifar100\n","\n","#Model testing\n","!python test.py tiny cifar100"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"a4avd_AZhU8h","executionInfo":{"status":"ok","timestamp":1650796196400,"user_tz":-300,"elapsed":1875558,"user":{"displayName":"Naveed Khan","userId":"05394460902808852358"}},"outputId":"d026aecc-80d9-4713-b441-c039fa6bac22"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n","169009152/169001437 [==============================] - 2s 0us/step\n","169017344/169001437 [==============================] - 2s 0us/step\n","2022-04-24 09:58:50.092780: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2022-04-24 10:29:11.663731: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n","WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, query_layer_call_fn while saving (showing 5 of 52). These functions will not be directly callable after loading.\n","2022-04-24 10:29:26.087736: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","CNN model performance is as given below.\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       100\n","           1       0.00      0.00      0.00       100\n","           2       0.00      0.00      0.00       100\n","           3       0.00      0.00      0.00       100\n","           4       0.00      0.00      0.00       100\n","           5       0.00      0.00      0.00       100\n","           6       0.00      0.00      0.00       100\n","           7       0.00      0.00      0.00       100\n","           8       0.00      0.00      0.00       100\n","           9       0.00      0.00      0.00       100\n","          10       0.00      0.00      0.00       100\n","          11       0.00      0.00      0.00       100\n","          12       0.00      0.00      0.00       100\n","          13       0.00      0.00      0.00       100\n","          14       0.00      0.00      0.00       100\n","          15       0.00      0.00      0.00       100\n","          16       0.00      0.00      0.00       100\n","          17       0.00      0.00      0.00       100\n","          18       0.01      1.00      0.02       100\n","          19       0.00      0.00      0.00       100\n","          20       0.00      0.00      0.00       100\n","          21       0.00      0.00      0.00       100\n","          22       0.00      0.00      0.00       100\n","          23       0.00      0.00      0.00       100\n","          24       0.00      0.00      0.00       100\n","          25       0.00      0.00      0.00       100\n","          26       0.00      0.00      0.00       100\n","          27       0.00      0.00      0.00       100\n","          28       0.00      0.00      0.00       100\n","          29       0.00      0.00      0.00       100\n","          30       0.00      0.00      0.00       100\n","          31       0.00      0.00      0.00       100\n","          32       0.00      0.00      0.00       100\n","          33       0.00      0.00      0.00       100\n","          34       0.00      0.00      0.00       100\n","          35       0.00      0.00      0.00       100\n","          36       0.00      0.00      0.00       100\n","          37       0.00      0.00      0.00       100\n","          38       0.00      0.00      0.00       100\n","          39       0.00      0.00      0.00       100\n","          40       0.00      0.00      0.00       100\n","          41       0.00      0.00      0.00       100\n","          42       0.00      0.00      0.00       100\n","          43       0.00      0.00      0.00       100\n","          44       0.00      0.00      0.00       100\n","          45       0.00      0.00      0.00       100\n","          46       0.00      0.00      0.00       100\n","          47       0.00      0.00      0.00       100\n","          48       0.00      0.00      0.00       100\n","          49       0.00      0.00      0.00       100\n","          50       0.00      0.00      0.00       100\n","          51       0.00      0.00      0.00       100\n","          52       0.00      0.00      0.00       100\n","          53       0.00      0.00      0.00       100\n","          54       0.00      0.00      0.00       100\n","          55       0.00      0.00      0.00       100\n","          56       0.00      0.00      0.00       100\n","          57       0.00      0.00      0.00       100\n","          58       0.00      0.00      0.00       100\n","          59       0.00      0.00      0.00       100\n","          60       0.00      0.00      0.00       100\n","          61       0.00      0.00      0.00       100\n","          62       0.00      0.00      0.00       100\n","          63       0.00      0.00      0.00       100\n","          64       0.00      0.00      0.00       100\n","          65       0.00      0.00      0.00       100\n","          66       0.00      0.00      0.00       100\n","          67       0.00      0.00      0.00       100\n","          68       0.00      0.00      0.00       100\n","          69       0.00      0.00      0.00       100\n","          70       0.00      0.00      0.00       100\n","          71       0.00      0.00      0.00       100\n","          72       0.00      0.00      0.00       100\n","          73       0.00      0.00      0.00       100\n","          74       0.00      0.00      0.00       100\n","          75       0.00      0.00      0.00       100\n","          76       0.00      0.00      0.00       100\n","          77       0.00      0.00      0.00       100\n","          78       0.00      0.00      0.00       100\n","          79       0.00      0.00      0.00       100\n","          80       0.00      0.00      0.00       100\n","          81       0.00      0.00      0.00       100\n","          82       0.00      0.00      0.00       100\n","          83       0.00      0.00      0.00       100\n","          84       0.00      0.00      0.00       100\n","          85       0.00      0.00      0.00       100\n","          86       0.00      0.00      0.00       100\n","          87       0.00      0.00      0.00       100\n","          88       0.00      0.00      0.00       100\n","          89       0.00      0.00      0.00       100\n","          90       0.00      0.00      0.00       100\n","          91       0.00      0.00      0.00       100\n","          92       0.00      0.00      0.00       100\n","          93       0.00      0.00      0.00       100\n","          94       0.00      0.00      0.00       100\n","          95       0.00      0.00      0.00       100\n","          96       0.00      0.00      0.00       100\n","          97       0.00      0.00      0.00       100\n","          98       0.00      0.00      0.00       100\n","          99       0.00      0.00      0.00       100\n","\n","    accuracy                           0.01     10000\n","   macro avg       0.00      0.01      0.00     10000\n","weighted avg       0.00      0.01      0.00     10000\n","\n","313/313 [==============================] - 1s 3ms/step - loss: 4.6052 - accuracy: 0.0100\n","CNN model loss on test set is: 4.605175495147705\n","Transformer model performance is as given below.\n","              precision    recall  f1-score   support\n","\n","           0       0.51      0.84      0.63       100\n","           1       0.56      0.61      0.58       100\n","           2       0.38      0.38      0.38       100\n","           3       0.30      0.23      0.26       100\n","           4       0.18      0.31      0.23       100\n","           5       0.38      0.52      0.44       100\n","           6       0.66      0.49      0.56       100\n","           7       0.69      0.42      0.52       100\n","           8       0.58      0.52      0.55       100\n","           9       0.84      0.48      0.61       100\n","          10       0.36      0.29      0.32       100\n","          11       0.45      0.30      0.36       100\n","          12       0.45      0.45      0.45       100\n","          13       0.41      0.38      0.39       100\n","          14       0.44      0.41      0.42       100\n","          15       0.37      0.28      0.32       100\n","          16       0.47      0.49      0.48       100\n","          17       0.43      0.66      0.52       100\n","          18       0.47      0.32      0.38       100\n","          19       0.42      0.36      0.39       100\n","          20       0.79      0.74      0.76       100\n","          21       0.63      0.67      0.65       100\n","          22       0.36      0.39      0.38       100\n","          23       0.75      0.58      0.66       100\n","          24       0.62      0.64      0.63       100\n","          25       0.31      0.21      0.25       100\n","          26       0.41      0.27      0.33       100\n","          27       0.28      0.32      0.30       100\n","          28       0.65      0.66      0.65       100\n","          29       0.60      0.37      0.46       100\n","          30       0.37      0.62      0.46       100\n","          31       0.37      0.63      0.46       100\n","          32       0.72      0.42      0.53       100\n","          33       0.37      0.44      0.40       100\n","          34       0.40      0.33      0.36       100\n","          35       0.28      0.24      0.26       100\n","          36       0.54      0.38      0.45       100\n","          37       0.39      0.39      0.39       100\n","          38       0.31      0.39      0.34       100\n","          39       0.55      0.56      0.56       100\n","          40       0.46      0.29      0.36       100\n","          41       0.68      0.73      0.70       100\n","          42       0.33      0.50      0.40       100\n","          43       0.31      0.57      0.40       100\n","          44       0.37      0.25      0.30       100\n","          45       0.28      0.35      0.31       100\n","          46       0.52      0.44      0.48       100\n","          47       0.68      0.39      0.50       100\n","          48       0.64      0.74      0.69       100\n","          49       0.58      0.57      0.57       100\n","          50       0.38      0.13      0.19       100\n","          51       0.35      0.51      0.41       100\n","          52       0.46      0.77      0.58       100\n","          53       0.54      0.75      0.63       100\n","          54       0.65      0.69      0.67       100\n","          55       0.15      0.10      0.12       100\n","          56       0.54      0.68      0.60       100\n","          57       0.60      0.39      0.47       100\n","          58       0.62      0.55      0.59       100\n","          59       0.42      0.31      0.36       100\n","          60       0.70      0.78      0.74       100\n","          61       0.63      0.42      0.50       100\n","          62       0.62      0.45      0.52       100\n","          63       0.48      0.47      0.47       100\n","          64       0.31      0.22      0.26       100\n","          65       0.37      0.22      0.27       100\n","          66       0.30      0.22      0.25       100\n","          67       0.53      0.29      0.37       100\n","          68       0.78      0.80      0.79       100\n","          69       0.85      0.62      0.72       100\n","          70       0.57      0.35      0.43       100\n","          71       0.59      0.75      0.66       100\n","          72       0.21      0.17      0.19       100\n","          73       0.40      0.30      0.34       100\n","          74       0.25      0.33      0.28       100\n","          75       0.53      0.77      0.63       100\n","          76       0.66      0.71      0.68       100\n","          77       0.39      0.23      0.29       100\n","          78       0.29      0.33      0.31       100\n","          79       0.57      0.30      0.39       100\n","          80       0.25      0.26      0.25       100\n","          81       0.54      0.50      0.52       100\n","          82       0.76      0.77      0.77       100\n","          83       0.46      0.31      0.37       100\n","          84       0.39      0.33      0.36       100\n","          85       0.42      0.72      0.53       100\n","          86       0.55      0.51      0.53       100\n","          87       0.36      0.65      0.46       100\n","          88       0.44      0.49      0.46       100\n","          89       0.38      0.68      0.49       100\n","          90       0.37      0.31      0.34       100\n","          91       0.59      0.57      0.58       100\n","          92       0.35      0.36      0.36       100\n","          93       0.31      0.29      0.30       100\n","          94       0.48      0.86      0.62       100\n","          95       0.45      0.54      0.49       100\n","          96       0.29      0.42      0.35       100\n","          97       0.34      0.49      0.40       100\n","          98       0.27      0.09      0.14       100\n","          99       0.63      0.40      0.49       100\n","\n","    accuracy                           0.46     10000\n","   macro avg       0.47      0.46      0.45     10000\n","weighted avg       0.47      0.46      0.45     10000\n","\n","313/313 [==============================] - 9s 27ms/step - loss: 2.0317 - accuracy: 0.4598 - top-5-accuracy: 0.7616\n","Transformer model loss on test set is: 2.031712532043457\n"]}]},{"cell_type":"markdown","source":["##Small Models"],"metadata":{"id":"0awL0Rp0g4xn"}},{"cell_type":"code","source":["#Model training\n","!python train.py small cifar100\n","\n","#Model testing\n","!python test.py small cifar100"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3mvED59VhXZ8","executionInfo":{"status":"ok","timestamp":1650798858040,"user_tz":-300,"elapsed":2578969,"user":{"displayName":"Naveed Khan","userId":"05394460902808852358"}},"outputId":"ec5c77f9-92de-4283-e8e1-030cfc8392ae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["2022-04-24 10:31:23.125034: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2022-04-24 11:13:13.878795: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n","WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, query_layer_call_fn while saving (showing 5 of 76). These functions will not be directly callable after loading.\n","2022-04-24 11:13:29.847203: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","CNN model performance is as given below.\n","              precision    recall  f1-score   support\n","\n","           0       0.55      0.47      0.51       100\n","           1       0.32      0.27      0.29       100\n","           2       0.29      0.14      0.19       100\n","           3       0.09      0.13      0.11       100\n","           4       0.06      0.05      0.06       100\n","           5       0.25      0.25      0.25       100\n","           6       0.19      0.24      0.21       100\n","           7       0.24      0.25      0.25       100\n","           8       0.35      0.44      0.39       100\n","           9       0.40      0.36      0.38       100\n","          10       0.13      0.16      0.14       100\n","          11       0.21      0.13      0.16       100\n","          12       0.25      0.19      0.22       100\n","          13       0.20      0.21      0.21       100\n","          14       0.16      0.16      0.16       100\n","          15       0.18      0.09      0.12       100\n","          16       0.29      0.26      0.27       100\n","          17       0.36      0.54      0.43       100\n","          18       0.24      0.15      0.18       100\n","          19       0.15      0.11      0.13       100\n","          20       0.50      0.61      0.55       100\n","          21       0.37      0.43      0.40       100\n","          22       0.29      0.20      0.24       100\n","          23       0.41      0.58      0.48       100\n","          24       0.40      0.49      0.44       100\n","          25       0.16      0.12      0.14       100\n","          26       0.26      0.17      0.20       100\n","          27       0.17      0.28      0.21       100\n","          28       0.41      0.52      0.46       100\n","          29       0.19      0.19      0.19       100\n","          30       0.22      0.41      0.29       100\n","          31       0.20      0.26      0.23       100\n","          32       0.31      0.17      0.22       100\n","          33       0.24      0.29      0.26       100\n","          34       0.19      0.14      0.16       100\n","          35       0.15      0.13      0.14       100\n","          36       0.41      0.33      0.36       100\n","          37       0.22      0.28      0.25       100\n","          38       0.14      0.15      0.15       100\n","          39       0.12      0.12      0.12       100\n","          40       0.27      0.20      0.23       100\n","          41       0.55      0.48      0.51       100\n","          42       0.17      0.32      0.23       100\n","          43       0.27      0.20      0.23       100\n","          44       0.11      0.12      0.12       100\n","          45       0.08      0.05      0.06       100\n","          46       0.21      0.08      0.12       100\n","          47       0.49      0.33      0.39       100\n","          48       0.45      0.55      0.49       100\n","          49       0.35      0.21      0.26       100\n","          50       0.07      0.05      0.06       100\n","          51       0.18      0.11      0.14       100\n","          52       0.48      0.58      0.53       100\n","          53       0.54      0.41      0.47       100\n","          54       0.39      0.39      0.39       100\n","          55       0.04      0.01      0.02       100\n","          56       0.27      0.40      0.33       100\n","          57       0.30      0.30      0.30       100\n","          58       0.28      0.20      0.23       100\n","          59       0.26      0.15      0.19       100\n","          60       0.72      0.61      0.66       100\n","          61       0.51      0.33      0.40       100\n","          62       0.39      0.38      0.38       100\n","          63       0.20      0.27      0.23       100\n","          64       0.06      0.11      0.08       100\n","          65       0.12      0.13      0.13       100\n","          66       0.12      0.19      0.15       100\n","          67       0.25      0.30      0.27       100\n","          68       0.47      0.53      0.50       100\n","          69       0.50      0.52      0.51       100\n","          70       0.30      0.24      0.27       100\n","          71       0.51      0.54      0.52       100\n","          72       0.11      0.05      0.07       100\n","          73       0.28      0.25      0.26       100\n","          74       0.15      0.19      0.17       100\n","          75       0.30      0.47      0.37       100\n","          76       0.46      0.49      0.47       100\n","          77       0.12      0.10      0.11       100\n","          78       0.10      0.05      0.07       100\n","          79       0.26      0.24      0.25       100\n","          80       0.09      0.08      0.09       100\n","          81       0.27      0.14      0.19       100\n","          82       0.60      0.59      0.59       100\n","          83       0.41      0.30      0.34       100\n","          84       0.18      0.19      0.18       100\n","          85       0.24      0.41      0.31       100\n","          86       0.27      0.34      0.30       100\n","          87       0.34      0.34      0.34       100\n","          88       0.20      0.19      0.20       100\n","          89       0.31      0.33      0.32       100\n","          90       0.24      0.12      0.16       100\n","          91       0.27      0.43      0.33       100\n","          92       0.20      0.15      0.17       100\n","          93       0.11      0.11      0.11       100\n","          94       0.71      0.58      0.64       100\n","          95       0.31      0.40      0.35       100\n","          96       0.29      0.26      0.27       100\n","          97       0.14      0.44      0.22       100\n","          98       0.15      0.09      0.11       100\n","          99       0.14      0.11      0.12       100\n","\n","    accuracy                           0.27     10000\n","   macro avg       0.27      0.27      0.27     10000\n","weighted avg       0.27      0.27      0.27     10000\n","\n","313/313 [==============================] - 1s 3ms/step - loss: 3.3769 - accuracy: 0.2720\n","CNN model loss on test set is: 3.3769006729125977\n","Transformer model performance is as given below.\n","              precision    recall  f1-score   support\n","\n","           0       0.75      0.65      0.70       100\n","           1       0.58      0.57      0.57       100\n","           2       0.41      0.39      0.40       100\n","           3       0.34      0.26      0.30       100\n","           4       0.23      0.36      0.28       100\n","           5       0.44      0.43      0.43       100\n","           6       0.63      0.53      0.58       100\n","           7       0.56      0.51      0.53       100\n","           8       0.55      0.59      0.57       100\n","           9       0.83      0.54      0.65       100\n","          10       0.36      0.24      0.29       100\n","          11       0.33      0.33      0.33       100\n","          12       0.57      0.47      0.52       100\n","          13       0.42      0.36      0.39       100\n","          14       0.49      0.33      0.40       100\n","          15       0.44      0.29      0.35       100\n","          16       0.63      0.40      0.49       100\n","          17       0.59      0.63      0.61       100\n","          18       0.49      0.29      0.36       100\n","          19       0.41      0.37      0.39       100\n","          20       0.75      0.74      0.74       100\n","          21       0.37      0.74      0.49       100\n","          22       0.58      0.30      0.39       100\n","          23       0.75      0.67      0.71       100\n","          24       0.55      0.66      0.60       100\n","          25       0.34      0.29      0.31       100\n","          26       0.49      0.40      0.44       100\n","          27       0.25      0.30      0.27       100\n","          28       0.60      0.66      0.63       100\n","          29       0.47      0.38      0.42       100\n","          30       0.37      0.68      0.48       100\n","          31       0.47      0.47      0.47       100\n","          32       0.48      0.46      0.47       100\n","          33       0.48      0.35      0.40       100\n","          34       0.35      0.46      0.39       100\n","          35       0.33      0.21      0.26       100\n","          36       0.42      0.47      0.44       100\n","          37       0.39      0.47      0.42       100\n","          38       0.19      0.47      0.27       100\n","          39       0.55      0.58      0.57       100\n","          40       0.60      0.34      0.43       100\n","          41       0.55      0.78      0.64       100\n","          42       0.30      0.52      0.38       100\n","          43       0.38      0.58      0.46       100\n","          44       0.24      0.22      0.23       100\n","          45       0.31      0.31      0.31       100\n","          46       0.40      0.32      0.35       100\n","          47       0.56      0.49      0.52       100\n","          48       0.53      0.80      0.64       100\n","          49       0.64      0.46      0.53       100\n","          50       0.41      0.17      0.24       100\n","          51       0.45      0.43      0.44       100\n","          52       0.43      0.86      0.58       100\n","          53       0.74      0.68      0.71       100\n","          54       0.70      0.59      0.64       100\n","          55       0.14      0.07      0.09       100\n","          56       0.66      0.60      0.63       100\n","          57       0.65      0.43      0.52       100\n","          58       0.62      0.46      0.53       100\n","          59       0.47      0.26      0.34       100\n","          60       0.78      0.73      0.76       100\n","          61       0.50      0.59      0.54       100\n","          62       0.54      0.67      0.60       100\n","          63       0.45      0.47      0.46       100\n","          64       0.19      0.28      0.23       100\n","          65       0.26      0.17      0.20       100\n","          66       0.30      0.21      0.25       100\n","          67       0.50      0.36      0.42       100\n","          68       0.82      0.77      0.79       100\n","          69       0.64      0.66      0.65       100\n","          70       0.47      0.61      0.53       100\n","          71       0.58      0.73      0.65       100\n","          72       0.15      0.09      0.11       100\n","          73       0.33      0.34      0.34       100\n","          74       0.36      0.20      0.26       100\n","          75       0.62      0.73      0.67       100\n","          76       0.66      0.73      0.70       100\n","          77       0.46      0.17      0.25       100\n","          78       0.34      0.34      0.34       100\n","          79       0.46      0.38      0.42       100\n","          80       0.22      0.13      0.16       100\n","          81       0.35      0.63      0.45       100\n","          82       0.84      0.75      0.79       100\n","          83       0.54      0.44      0.49       100\n","          84       0.41      0.26      0.32       100\n","          85       0.63      0.62      0.63       100\n","          86       0.40      0.59      0.48       100\n","          87       0.50      0.63      0.56       100\n","          88       0.36      0.43      0.39       100\n","          89       0.37      0.64      0.47       100\n","          90       0.32      0.44      0.37       100\n","          91       0.56      0.60      0.58       100\n","          92       0.43      0.16      0.23       100\n","          93       0.33      0.23      0.27       100\n","          94       0.73      0.76      0.75       100\n","          95       0.45      0.51      0.48       100\n","          96       0.35      0.34      0.35       100\n","          97       0.31      0.56      0.40       100\n","          98       0.32      0.18      0.23       100\n","          99       0.59      0.49      0.54       100\n","\n","    accuracy                           0.46     10000\n","   macro avg       0.47      0.46      0.46     10000\n","weighted avg       0.47      0.46      0.46     10000\n","\n","313/313 [==============================] - 13s 38ms/step - loss: 2.0286 - accuracy: 0.4629 - top-5-accuracy: 0.7649\n","Transformer model loss on test set is: 2.0285682678222656\n"]}]},{"cell_type":"markdown","source":["##Base Models"],"metadata":{"id":"mBl7Roo1g_ra"}},{"cell_type":"code","source":["#Model training\n","!python train.py base cifar100\n","\n","#Model testing\n","!python test.py base cifar100"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jvVWfFsMhZDw","outputId":"790639df-0857-4f0d-f0e5-72af3c58542c","executionInfo":{"status":"ok","timestamp":1650807798475,"user_tz":-300,"elapsed":3324329,"user":{"displayName":"Naveed Khan","userId":"05394460902808852358"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz\n","169009152/169001437 [==============================] - 2s 0us/step\n","169017344/169001437 [==============================] - 2s 0us/step\n","2022-04-24 12:48:04.072164: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2022-04-24 13:42:12.626744: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n","WARNING:absl:Found untraced functions such as dense_layer_call_fn, dense_layer_call_and_return_conditional_losses, embedding_layer_call_fn, embedding_layer_call_and_return_conditional_losses, query_layer_call_fn while saving (showing 5 of 100). These functions will not be directly callable after loading.\n","2022-04-24 13:42:30.501807: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","CNN model performance is as given below.\n","              precision    recall  f1-score   support\n","\n","           0       0.53      0.69      0.60       100\n","           1       0.53      0.42      0.47       100\n","           2       0.28      0.22      0.25       100\n","           3       0.15      0.11      0.13       100\n","           4       0.17      0.16      0.17       100\n","           5       0.26      0.17      0.21       100\n","           6       0.32      0.28      0.30       100\n","           7       0.35      0.28      0.31       100\n","           8       0.31      0.33      0.32       100\n","           9       0.47      0.35      0.40       100\n","          10       0.09      0.13      0.11       100\n","          11       0.14      0.16      0.15       100\n","          12       0.31      0.36      0.33       100\n","          13       0.16      0.20      0.18       100\n","          14       0.22      0.32      0.26       100\n","          15       0.32      0.20      0.25       100\n","          16       0.29      0.38      0.33       100\n","          17       0.48      0.44      0.46       100\n","          18       0.19      0.18      0.19       100\n","          19       0.23      0.23      0.23       100\n","          20       0.60      0.55      0.58       100\n","          21       0.37      0.47      0.41       100\n","          22       0.30      0.25      0.27       100\n","          23       0.54      0.38      0.44       100\n","          24       0.61      0.56      0.58       100\n","          25       0.15      0.11      0.13       100\n","          26       0.25      0.17      0.20       100\n","          27       0.15      0.13      0.14       100\n","          28       0.44      0.40      0.42       100\n","          29       0.27      0.26      0.27       100\n","          30       0.30      0.36      0.33       100\n","          31       0.35      0.20      0.25       100\n","          32       0.19      0.22      0.21       100\n","          33       0.24      0.21      0.22       100\n","          34       0.22      0.28      0.25       100\n","          35       0.16      0.20      0.18       100\n","          36       0.29      0.37      0.32       100\n","          37       0.22      0.26      0.24       100\n","          38       0.21      0.17      0.19       100\n","          39       0.37      0.41      0.39       100\n","          40       0.18      0.22      0.20       100\n","          41       0.45      0.52      0.48       100\n","          42       0.37      0.27      0.31       100\n","          43       0.46      0.34      0.39       100\n","          44       0.10      0.07      0.08       100\n","          45       0.16      0.22      0.19       100\n","          46       0.16      0.25      0.20       100\n","          47       0.43      0.39      0.41       100\n","          48       0.36      0.60      0.45       100\n","          49       0.38      0.53      0.44       100\n","          50       0.17      0.09      0.12       100\n","          51       0.26      0.19      0.22       100\n","          52       0.58      0.53      0.55       100\n","          53       0.44      0.55      0.49       100\n","          54       0.38      0.37      0.38       100\n","          55       0.09      0.07      0.08       100\n","          56       0.43      0.42      0.43       100\n","          57       0.29      0.29      0.29       100\n","          58       0.31      0.44      0.37       100\n","          59       0.26      0.38      0.31       100\n","          60       0.72      0.62      0.67       100\n","          61       0.40      0.38      0.39       100\n","          62       0.44      0.46      0.45       100\n","          63       0.38      0.28      0.32       100\n","          64       0.13      0.10      0.11       100\n","          65       0.12      0.09      0.10       100\n","          66       0.23      0.27      0.25       100\n","          67       0.26      0.31      0.28       100\n","          68       0.75      0.49      0.59       100\n","          69       0.39      0.59      0.47       100\n","          70       0.40      0.38      0.39       100\n","          71       0.61      0.46      0.53       100\n","          72       0.18      0.13      0.15       100\n","          73       0.31      0.13      0.18       100\n","          74       0.20      0.15      0.17       100\n","          75       0.60      0.61      0.60       100\n","          76       0.50      0.56      0.53       100\n","          77       0.22      0.22      0.22       100\n","          78       0.08      0.04      0.05       100\n","          79       0.32      0.15      0.20       100\n","          80       0.17      0.10      0.13       100\n","          81       0.29      0.23      0.26       100\n","          82       0.70      0.64      0.67       100\n","          83       0.28      0.26      0.27       100\n","          84       0.14      0.19      0.16       100\n","          85       0.46      0.26      0.33       100\n","          86       0.33      0.41      0.36       100\n","          87       0.30      0.32      0.31       100\n","          88       0.26      0.32      0.29       100\n","          89       0.30      0.25      0.27       100\n","          90       0.30      0.31      0.31       100\n","          91       0.31      0.44      0.36       100\n","          92       0.24      0.27      0.25       100\n","          93       0.17      0.21      0.19       100\n","          94       0.53      0.62      0.57       100\n","          95       0.29      0.52      0.37       100\n","          96       0.35      0.26      0.30       100\n","          97       0.23      0.35      0.28       100\n","          98       0.12      0.13      0.12       100\n","          99       0.27      0.37      0.31       100\n","\n","    accuracy                           0.31     10000\n","   macro avg       0.32      0.31      0.31     10000\n","weighted avg       0.32      0.31      0.31     10000\n","\n","313/313 [==============================] - 1s 3ms/step - loss: 4.8371 - accuracy: 0.3119\n","CNN model loss on test set is: 4.837136745452881\n","Transformer model performance is as given below.\n","              precision    recall  f1-score   support\n","\n","           0       0.67      0.72      0.69       100\n","           1       0.62      0.55      0.59       100\n","           2       0.31      0.37      0.34       100\n","           3       0.31      0.15      0.20       100\n","           4       0.23      0.35      0.28       100\n","           5       0.29      0.58      0.38       100\n","           6       0.66      0.44      0.53       100\n","           7       0.72      0.43      0.54       100\n","           8       0.43      0.58      0.49       100\n","           9       0.71      0.58      0.64       100\n","          10       0.40      0.25      0.31       100\n","          11       0.37      0.25      0.30       100\n","          12       0.48      0.50      0.49       100\n","          13       0.37      0.31      0.34       100\n","          14       0.47      0.34      0.40       100\n","          15       0.36      0.36      0.36       100\n","          16       0.41      0.52      0.46       100\n","          17       0.52      0.70      0.60       100\n","          18       0.58      0.41      0.48       100\n","          19       0.43      0.42      0.43       100\n","          20       0.56      0.79      0.66       100\n","          21       0.62      0.71      0.66       100\n","          22       0.40      0.34      0.37       100\n","          23       0.80      0.66      0.72       100\n","          24       0.68      0.67      0.67       100\n","          25       0.32      0.23      0.27       100\n","          26       0.49      0.30      0.37       100\n","          27       0.31      0.33      0.32       100\n","          28       0.68      0.64      0.66       100\n","          29       0.59      0.30      0.40       100\n","          30       0.43      0.56      0.48       100\n","          31       0.45      0.53      0.49       100\n","          32       0.61      0.42      0.50       100\n","          33       0.51      0.36      0.42       100\n","          34       0.34      0.47      0.39       100\n","          35       0.25      0.43      0.32       100\n","          36       0.44      0.51      0.47       100\n","          37       0.37      0.37      0.37       100\n","          38       0.23      0.39      0.29       100\n","          39       0.71      0.56      0.63       100\n","          40       0.67      0.29      0.41       100\n","          41       0.71      0.67      0.69       100\n","          42       0.37      0.42      0.39       100\n","          43       0.41      0.52      0.46       100\n","          44       0.22      0.28      0.25       100\n","          45       0.33      0.35      0.34       100\n","          46       0.36      0.28      0.31       100\n","          47       0.73      0.44      0.55       100\n","          48       0.59      0.77      0.67       100\n","          49       0.56      0.48      0.52       100\n","          50       0.38      0.15      0.21       100\n","          51       0.44      0.41      0.42       100\n","          52       0.46      0.83      0.59       100\n","          53       0.58      0.81      0.67       100\n","          54       0.67      0.61      0.64       100\n","          55       0.19      0.08      0.11       100\n","          56       0.65      0.58      0.61       100\n","          57       0.41      0.38      0.40       100\n","          58       0.59      0.51      0.55       100\n","          59       0.42      0.37      0.39       100\n","          60       0.80      0.72      0.76       100\n","          61       0.55      0.50      0.52       100\n","          62       0.54      0.56      0.55       100\n","          63       0.58      0.44      0.50       100\n","          64       0.27      0.20      0.23       100\n","          65       0.21      0.15      0.17       100\n","          66       0.35      0.14      0.20       100\n","          67       0.48      0.36      0.41       100\n","          68       0.77      0.83      0.80       100\n","          69       0.58      0.74      0.65       100\n","          70       0.59      0.33      0.42       100\n","          71       0.70      0.64      0.67       100\n","          72       0.12      0.10      0.11       100\n","          73       0.37      0.45      0.41       100\n","          74       0.28      0.23      0.25       100\n","          75       0.53      0.77      0.63       100\n","          76       0.59      0.72      0.65       100\n","          77       0.29      0.30      0.29       100\n","          78       0.37      0.34      0.35       100\n","          79       0.45      0.36      0.40       100\n","          80       0.31      0.16      0.21       100\n","          81       0.28      0.74      0.41       100\n","          82       0.85      0.76      0.80       100\n","          83       0.50      0.46      0.48       100\n","          84       0.47      0.28      0.35       100\n","          85       0.65      0.52      0.58       100\n","          86       0.38      0.52      0.44       100\n","          87       0.46      0.62      0.53       100\n","          88       0.39      0.37      0.38       100\n","          89       0.45      0.62      0.52       100\n","          90       0.43      0.35      0.38       100\n","          91       0.50      0.58      0.54       100\n","          92       0.36      0.44      0.39       100\n","          93       0.38      0.21      0.27       100\n","          94       0.53      0.75      0.62       100\n","          95       0.48      0.59      0.53       100\n","          96       0.46      0.31      0.37       100\n","          97       0.35      0.56      0.43       100\n","          98       0.17      0.17      0.17       100\n","          99       0.49      0.47      0.48       100\n","\n","    accuracy                           0.46     10000\n","   macro avg       0.47      0.46      0.45     10000\n","weighted avg       0.47      0.46      0.45     10000\n","\n","313/313 [==============================] - 17s 49ms/step - loss: 2.0352 - accuracy: 0.4597 - top-5-accuracy: 0.7606\n","Transformer model loss on test set is: 2.0351686477661133\n"]}]}]}