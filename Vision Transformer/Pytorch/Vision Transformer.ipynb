{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNpfOKzxy+uqaA8LhdxCRgX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","source":["#Download dataset and install packages\n","%%capture\n","!wget https://madm.dfki.de/files/sentinel/EuroSATallBands.zip --no-check-certificate\n","!unzip -q EuroSATallBands.zip\n","!pip install rasterio\n","!pip install einops"],"metadata":{"id":"Yqzx_znOFofK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Required Packages"],"metadata":{"id":"SKDK4-TBFHn5"}},{"cell_type":"code","source":["#Import packages\n","import os\n","import glob\n","import numpy as np\n","import rasterio as rio\n","from rasterio.plot import reshape_as_image\n","import matplotlib.pyplot as plt\n","import torchvision\n","import torch\n","import torch.nn.functional as F\n","from torch import nn\n","from torchvision import transforms\n","from torch.utils.data import Dataset\n","from sklearn.model_selection import train_test_split\n","from torch.utils.data import DataLoader\n","import torch.nn as nn\n","import tqdm \n","from torch import optim\n","from math import sqrt\n","from einops import rearrange, repeat\n","from einops.layers.torch import Rearrange\n","import re"],"metadata":{"id":"ckXpSRGYF8x-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Prepare Dataset"],"metadata":{"id":"sOtOV2w5Dvmm"}},{"cell_type":"code","source":["#Data directory\n","eurosat_dir = \"/content/ds/images/remote_sensing/otherDatasets/sentinel_2/tif\"\n","\n","#Classes\n","classes = [\n","    \"AnnualCrop\",\n","    \"Forest\",\n","    \"HerbaceousVegetation\",\n","    \"Highway\",\n","    \"Industrial\",\n","    \"Pasture\",\n","    \"PermanentCrop\",\n","    \"Residential\",\n","    \"River\",\n","    \"SeaLake\",\n","]\n","\n","#Class labels\n","class_labels = {\n","    0: \"AnnualCrop\",\n","    1: \"Forest\",\n","    2: \"HerbaceousVegetation\",\n","    3: \"Highway\",\n","    4: \"Industrial\",\n","    5: \"Pasture\",\n","    6: \"PermanentCrop\",\n","    7: \"Residential\",\n","    8: \"River\",\n","    9: \"SeaLake\",\n","}\n","\n","#Data augmentation\n","transform = transforms.Compose([\n","transforms.ToTensor(),\n","transforms.RandomHorizontalFlip(),\n","transforms.RandomVerticalFlip(),\n","transforms.RandomRotation(90)\n","])\n","\n","#Prepare dataset\n","class EurosatDataset(Dataset):\n","    def __init__(self, data_dir, classes, transform=None):\n","        self.data_dir = data_dir\n","        self.classes = classes\n","        self.transform = transform\n","        self.file_paths = []\n","        self.labels = []\n","\n","        for i, class_name in self.classes.items():\n","            class_dir = os.path.join(self.data_dir, class_name)\n","            for file_name in os.listdir(class_dir):\n","                file_path = os.path.join(class_dir, file_name)\n","                self.file_paths.append(file_path)\n","                self.labels.append(i)\n","\n","    def __len__(self):\n","        return len(self.file_paths)\n","\n","    def __getitem__(self, index):\n","            file_path = self.file_paths[index]\n","            with rio.open(file_path, \"r\") as src:\n","                # read all the bands in the file\n","                img = src.read()\n","            img = img.astype(np.int32)\n","            img = img / 10000\n","            # move channel 13 to after channel 8\n","            img = np.concatenate((img[:8,:,:], img[12:13,:,:], img[9:10,:,:], img[11:13,:,:]), axis=0)\n","            # calculate NDVI\n","            ndvi = (img[8,:,:] - img[3,:,:]) / (img[8,:,:] + img[3,:,:] + 1e-10)\n","            ndvi = ndvi.astype(np.float32)\n","            # append NDVI band to tensor\n","            img = np.concatenate((img, ndvi[np.newaxis,:,:]), axis=0)\n","            \n","            img = np.concatenate((img[0:4,:,:], img[12:13,:,:]), axis=0)\n","            img = img[1:4,:,:]\n","            if self.transform is not None:\n","                img = self.transform(img)\n","            \n","                #img = img.permute(1, 0, 2)\n","                img = img.permute(1,2,0)\n","            label = self.labels[index]\n","            return img, label\n","\n","# Instantiate the dataset\n","dataset = EurosatDataset(eurosat_dir, class_labels, transform)\n","\n","# Split the data into training and testing sets\n","train_indices, test_indices = train_test_split(range(len(dataset)), test_size=0.2, stratify=dataset.labels)\n","train_dataset = torch.utils.data.Subset(dataset, train_indices)\n","test_dataset = torch.utils.data.Subset(dataset, test_indices)\n","\n","# Define the data loaders\n","batch_size = 32\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"],"metadata":{"id":"WrYlqWVVGKzC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Vision Transformer Model Design"],"metadata":{"id":"6jxGbBWaDyFm"}},{"cell_type":"code","source":["# helpers\n","def pair(t):\n","    return t if isinstance(t, tuple) else (t, t)\n","\n","# classes\n","class PreNorm(nn.Module):\n","    def __init__(self, dim, fn):\n","        super().__init__()\n","        self.norm = nn.LayerNorm(dim)\n","        self.fn = fn\n","    def forward(self, x, **kwargs):\n","        return self.fn(self.norm(x), **kwargs)\n","\n","class FeedForward(nn.Module):\n","    def __init__(self, dim, hidden_dim, dropout = 0.):\n","        super().__init__()\n","        self.net = nn.Sequential(\n","            nn.Linear(dim, hidden_dim),\n","            nn.GELU(),\n","            nn.Dropout(dropout),\n","            nn.Linear(hidden_dim, dim),\n","            nn.Dropout(dropout)\n","        )\n","    def forward(self, x):\n","        return self.net(x)\n","\n","class LSA(nn.Module):\n","    def __init__(self, dim, heads = 8, dim_head = 64, dropout = 0.):\n","        super().__init__()\n","        inner_dim = dim_head *  heads\n","        self.heads = heads\n","        self.temperature = nn.Parameter(torch.log(torch.tensor(dim_head ** -0.5)))\n","\n","        self.attend = nn.Softmax(dim = -1)\n","        self.dropout = nn.Dropout(dropout)\n","\n","        self.to_qkv = nn.Linear(dim, inner_dim * 3, bias = False)\n","\n","        self.to_out = nn.Sequential(\n","            nn.Linear(inner_dim, dim),\n","            nn.Dropout(dropout)\n","        )\n","\n","    def forward(self, x):\n","        qkv = self.to_qkv(x).chunk(3, dim = -1)\n","        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> b h n d', h = self.heads), qkv)\n","\n","        dots = torch.matmul(q, k.transpose(-1, -2)) * self.temperature.exp()\n","\n","        mask = torch.eye(dots.shape[-1], device = dots.device, dtype = torch.bool)\n","        mask_value = -torch.finfo(dots.dtype).max\n","        dots = dots.masked_fill(mask, mask_value)\n","\n","        attn = self.attend(dots)\n","        attn = self.dropout(attn)\n","\n","        out = torch.matmul(attn, v)\n","        out = rearrange(out, 'b h n d -> b n (h d)')\n","        return self.to_out(out)\n","\n","class Transformer(nn.Module):\n","    def __init__(self, dim, depth, heads, dim_head, mlp_dim, dropout = 0.):\n","        super().__init__()\n","        self.layers = nn.ModuleList([])\n","        for _ in range(depth):\n","            self.layers.append(nn.ModuleList([\n","                PreNorm(dim, LSA(dim, heads = heads, dim_head = dim_head, dropout = dropout)),\n","                PreNorm(dim, FeedForward(dim, mlp_dim, dropout = dropout))\n","            ]))\n","    def forward(self, x):\n","        for attn, ff in self.layers:\n","            x = attn(x) + x\n","            x = ff(x) + x\n","        return x\n","\n","class SPT(nn.Module):\n","    def __init__(self, *, dim, patch_size, channels = 3):\n","        super().__init__()\n","        patch_dim = patch_size * patch_size * 5 * channels\n","\n","        self.to_patch_tokens = nn.Sequential(\n","            Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1 = patch_size, p2 = patch_size),\n","            nn.LayerNorm(patch_dim),\n","            nn.Linear(patch_dim, dim)\n","        )\n","\n","    def forward(self, x):\n","        shifts = ((1, -1, 0, 0), (-1, 1, 0, 0), (0, 0, 1, -1), (0, 0, -1, 1))\n","        shifted_x = list(map(lambda shift: F.pad(x, shift), shifts))\n","        x_with_shifts = torch.cat((x, *shifted_x), dim = 1)\n","        return self.to_patch_tokens(x_with_shifts)\n","\n","class ViT(nn.Module):\n","    def __init__(self, *, image_size, patch_size, num_classes, dim, depth, heads, mlp_dim, pool = 'cls', channels = 3, dim_head = 64, dropout = 0., emb_dropout = 0.):\n","        super().__init__()\n","        image_height, image_width = pair(image_size)\n","        patch_height, patch_width = pair(patch_size)\n","\n","        assert image_height % patch_height == 0 and image_width % patch_width == 0, 'Image dimensions must be divisible by the patch size.'\n","\n","        num_patches = (image_height // patch_height) * (image_width // patch_width)\n","        patch_dim = channels * patch_height * patch_width\n","        assert pool in {'cls', 'mean'}, 'pool type must be either cls (cls token) or mean (mean pooling)'\n","\n","        self.to_patch_embedding = SPT(dim = dim, patch_size = patch_size, channels = channels)\n","\n","        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, dim))\n","        self.cls_token = nn.Parameter(torch.randn(1, 1, dim))\n","        self.dropout = nn.Dropout(emb_dropout)\n","\n","        self.transformer = Transformer(dim, depth, heads, dim_head, mlp_dim, dropout)\n","\n","        self.pool = pool\n","        self.to_latent = nn.Identity()\n","\n","        self.mlp_head = nn.Sequential(\n","            nn.LayerNorm(dim),\n","            nn.Linear(dim, num_classes)\n","        )\n","\n","    def forward(self, img):\n","        x = self.to_patch_embedding(img)\n","        b, n, _ = x.shape\n","\n","        cls_tokens = repeat(self.cls_token, '() n d -> b n d', b = b)\n","        x = torch.cat((cls_tokens, x), dim=1)\n","        x += self.pos_embedding[:, :(n + 1)]\n","        x = self.dropout(x)\n","\n","        x = self.transformer(x)\n","\n","        x = x.mean(dim = 1) if self.pool == 'mean' else x[:, 0]\n","\n","        x = self.to_latent(x)\n","        return self.mlp_head(x)\n","\n","#Create model\n","model = ViT(\n","    image_size = 64,\n","    patch_size = 4,\n","    num_classes = 10,\n","    dim = 1024,\n","    depth = 6,\n","    heads = 16,\n","    mlp_dim = 1024,\n","    #Regularization   \n","    dropout = 0.01,\n","    emb_dropout = 0.01\n",")\n","\n","#Check for GPU\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Transfer model to compute device\n","model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nk0od-9QWGg9","executionInfo":{"status":"ok","timestamp":1684526066927,"user_tz":-300,"elapsed":3,"user":{"displayName":"Naveed Khan","userId":"05394460902808852358"}},"outputId":"47addd0f-06be-4a47-b438-b2db34db5cc0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["ViT(\n","  (to_patch_embedding): SPT(\n","    (to_patch_tokens): Sequential(\n","      (0): Rearrange('b c (h p1) (w p2) -> b (h w) (p1 p2 c)', p1=4, p2=4)\n","      (1): LayerNorm((240,), eps=1e-05, elementwise_affine=True)\n","      (2): Linear(in_features=240, out_features=1024, bias=True)\n","    )\n","  )\n","  (dropout): Dropout(p=0.01, inplace=False)\n","  (transformer): Transformer(\n","    (layers): ModuleList(\n","      (0-5): 6 x ModuleList(\n","        (0): PreNorm(\n","          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fn): LSA(\n","            (attend): Softmax(dim=-1)\n","            (dropout): Dropout(p=0.01, inplace=False)\n","            (to_qkv): Linear(in_features=1024, out_features=3072, bias=False)\n","            (to_out): Sequential(\n","              (0): Linear(in_features=1024, out_features=1024, bias=True)\n","              (1): Dropout(p=0.01, inplace=False)\n","            )\n","          )\n","        )\n","        (1): PreNorm(\n","          (norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","          (fn): FeedForward(\n","            (net): Sequential(\n","              (0): Linear(in_features=1024, out_features=1024, bias=True)\n","              (1): GELU(approximate='none')\n","              (2): Dropout(p=0.01, inplace=False)\n","              (3): Linear(in_features=1024, out_features=1024, bias=True)\n","              (4): Dropout(p=0.01, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","    )\n","  )\n","  (to_latent): Identity()\n","  (mlp_head): Sequential(\n","    (0): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n","    (1): Linear(in_features=1024, out_features=10, bias=True)\n","  )\n",")"]},"metadata":{},"execution_count":28}]},{"cell_type":"markdown","source":["#Model Training"],"metadata":{"id":"Cx-8fyJyEcZ9"}},{"cell_type":"code","source":["num_epochs = 2\n","# Init collection of training epoch losses\n","train_epoch_losses = []\n","train_epoch_accs = []\n","\n","# Set the model in training mode\n","model.train()\n","\n","# Define the optimization criterion / loss function\n","cross_entropy = nn.CrossEntropyLoss()\n","\n","# Define learning rate and optimization strategy\n","learning_rate = 0.001\n","\n","optimizer = optim.Adam(params=model.parameters(), lr=learning_rate)\n","\n","# Train for n epochs\n","for epoch in range(num_epochs):\n","    \n","    # Init collection of mini-batch losses\n","    train_mini_batch_losses = []\n","    train_mini_batch_accs = []\n","    train_loader_progress = tqdm.tqdm(train_loader)\n","\n","    # Update for each min-batch\n","    for i, (x, y) in enumerate(train_loader_progress):\n","        \n","        # Transfer data to compute device\n","        x, y = x.to(device), y.to(device)\n","        # Forward pass\n","        x = x.float()\n","        pred = model(x)\n","        # Reset model's gradients\n","        model.zero_grad()\n","        # Compute loss\n","        loss = cross_entropy(pred, y)\n","        acc = (pred.argmax(dim=1) == y).float().mean() * 100\n","        # Run backward pass\n","        loss.backward()\n","        # Update network paramaters\n","        optimizer.step()\n","        \n","        # Store mini-batch losses\n","        train_mini_batch_losses.append(loss.data.item())\n","        train_loader_progress.set_description(f\"Loss: {loss.item():0.5f}\")\n","        train_mini_batch_accs.append(acc.item())    \n","        train_loader_progress.set_description(f\"Loss: {loss.item():0.5f} - Acc: {acc.item():0.2f}%\")\n","\n","    # Compute epoch loss\n","    train_epoch_loss = np.mean(train_mini_batch_losses)\n","    train_epoch_losses.append(train_epoch_loss)\n","    train_epoch_acc = np.mean(train_mini_batch_accs)\n","    train_epoch_accs.append(train_epoch_acc)\n","\n","    print(f\"Epoch {epoch} - Loss: {train_epoch_loss:0.5f} - Acc: {train_epoch_acc:0.2f}%\") \n","    # Get the last accuracy value\n","    last_acc = train_epoch_accs[-1]\n","    # Check if the last value is larger than all previous values\n","    if all(last_acc > acc for acc in train_epoch_accs[:-1]):\n","      # Save final model \n","      torch.save(model.state_dict(), '/content/model.pt')\n","\n","torch.save(model.state_dict(), '/content/model_final.pt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dkpiz8ZILHZw","executionInfo":{"status":"ok","timestamp":1684527205743,"user_tz":-300,"elapsed":1136027,"user":{"displayName":"Naveed Khan","userId":"05394460902808852358"}},"outputId":"f6c4863e-0d48-4792-db18-109b0093531c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Loss: 2.27870 - Acc: 12.50%: 100%|██████████| 675/675 [09:29<00:00,  1.19it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 0 - Loss: 2.40991 - Acc: 11.43%\n"]},{"output_type":"stream","name":"stderr","text":["Loss: 2.31996 - Acc: 15.62%: 100%|██████████| 675/675 [09:24<00:00,  1.20it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1 - Loss: 2.24696 - Acc: 15.20%\n"]}]},{"cell_type":"markdown","source":["#Model Evaluation"],"metadata":{"id":"E0Mhl2PbEy01"}},{"cell_type":"code","source":["#Loss criterion\n","criterion = nn.CrossEntropyLoss()\n","\n","# Set the model to evaluation mode\n","model.eval()\n","# Initialize some variables to keep track of the accuracy and loss\n","correct = 0\n","total = 0\n","test_loss = 0\n","\n","# Turn off gradients\n","with torch.no_grad():\n","    # Loop through the test data in batches\n","    for images, labels in test_loader:\n","        # Convert the images and labels to the correct datatype\n","        images = images.float().to(device)\n","        labels = labels.long().to(device)\n","        # Make predictions using the model\n","        outputs = model(images)\n","        # Calculate the loss\n","        loss = criterion(outputs, labels)\n","        test_loss += loss.item()\n","        # Get the predicted classes\n","        _, predicted = torch.max(outputs.data, 1)\n","        # Update the correct and total counts\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","# Print the accuracy and loss\n","print('Accuracy on test dataset: {:.2f}%'.format(100 * correct / total))\n","print('Average test loss: {:.4f}'.format(test_loss / len(test_loader)))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QCgWqwEjLsp_","executionInfo":{"status":"ok","timestamp":1684527284177,"user_tz":-300,"elapsed":66089,"user":{"displayName":"Naveed Khan","userId":"05394460902808852358"}},"outputId":"824a7573-9d55-490b-ac2b-d8d0a4827afd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy on test dataset: 14.78%\n","Average test loss: 2.2011\n"]}]}]}